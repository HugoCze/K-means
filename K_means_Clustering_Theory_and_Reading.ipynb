{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0093fe3d",
   "metadata": {},
   "source": [
    "# K-Means(Algorytm CentroidÃ³w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b595c",
   "metadata": {},
   "source": [
    "Methods to predict the unlabeled data. Often there will be a need to create the groups of data instead of trying to predict classes or values. This sort of problems is called clustring. We can think of it as a way to create clusters. To be more specific there will be cases that will demand to cluster customer data into distinct groups. We can try to cluster some desises into benign and the deadly ones. But there is no guarantee that the cluster will fall into the correct lines. \n",
    "\n",
    "K-means clustering - unsupervised learning algorithm - It will attempt to group similair cluster together. \n",
    "\n",
    "- Clustering similiar documetns\n",
    "- Clustering based on features\n",
    "- Market segmentation\n",
    "- Identify similair physical groups\n",
    "\n",
    "There are some particluar steps for K-means clustring: \n",
    "\n",
    "- The analyst needs to setup the number of cluster. Our \"K\" value. It happens before we create the model. That means the analyst needs to use the domain knowledge to choose correct K value. \n",
    "- Then the random point assigment happens for each cluster. For each cluster it is going to compute the cluster centroid by taking the mean vectors points of the cluster. \n",
    "- After that it will assign each point to the cluster wheter the point the most centered(centroid). \n",
    "\n",
    "There are no pros and cons of assining the cluster. There is however the mathematical elbow method. \n",
    "\n",
    "Is called the elbow method. First of all we are computing the sum o squared error (SSE) for values of k e.g 2,4,6,8\n",
    "The SSE is defined as the sum of the squared distance between each member of the cluster and its centroid. \n",
    "\n",
    "Then we suppose to plot K against the SSE. The error suppose to decrase as K gets larger. \n",
    "The idea behind this is to choose the K at which the SSE decreases abruptly. This produces the elbow effect in the graf. \n",
    "\n",
    "While looking at the plot. We need to find where the abroubt values breaks and creates something shaped as the bending arm. \n",
    "PySpark as it self does not supply the plotting method but we will be using matplotlib to fulfill this one. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0569be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/Spark/spark-3.3.0-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8750d47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/15 10:00:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/15 10:00:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('K-meansClusteringTheory').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180b1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524ca28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/15 10:02:37 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataset = spark.read.format('libsvm').load('sample_kmeans_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92092de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|           (3,[],[])|\n",
      "|  1.0|(3,[0,1,2],[0.1,0...|\n",
      "|  2.0|(3,[0,1,2],[0.2,0...|\n",
      "|  3.0|(3,[0,1,2],[9.0,9...|\n",
      "|  4.0|(3,[0,1,2],[9.1,9...|\n",
      "|  5.0|(3,[0,1,2],[9.2,9...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3d5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = dataset.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced31b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|           (3,[],[])|\n",
      "|(3,[0,1,2],[0.1,0...|\n",
      "|(3,[0,1,2],[0.2,0...|\n",
      "|(3,[0,1,2],[9.0,9...|\n",
      "|(3,[0,1,2],[9.1,9...|\n",
      "|(3,[0,1,2],[9.2,9...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daae4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the kmeans: \n",
    " # setK represent the K value setting. Here we are following the documentation. \n",
    " # setSeed - the place of centriod is by default randomly choosen. setSeed() works in case we would like to come back to our \n",
    "  # project and and have quote to quote random setting. \n",
    "    \n",
    "kmeans = KMeans().setK(3).setSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "047a8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans only need the features column. The other type of operation would require the label Column as well. \n",
    "model = kmeans.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "756a094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated in 3.0.0\n",
    "# wssse = model.computeCost(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c5515d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Solution since PySpark 3.0.0\n",
    "wssse = model.summary.trainingCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faf374db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07499999999994544\n"
     ]
    }
   ],
   "source": [
    "# The within sum of squared errors\n",
    "print(wssse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "420dfced",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = model.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8e15f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9.1, 9.1, 9.1]), array([0.05, 0.05, 0.05]), array([0.2, 0.2, 0.2])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e00e88ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|           (3,[],[])|\n",
      "|(3,[0,1,2],[0.1,0...|\n",
      "|(3,[0,1,2],[0.2,0...|\n",
      "|(3,[0,1,2],[9.0,9...|\n",
      "|(3,[0,1,2],[9.1,9...|\n",
      "|(3,[0,1,2],[9.2,9...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d043106",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.transform(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ad33ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|           (3,[],[])|         1|\n",
      "|(3,[0,1,2],[0.1,0...|         1|\n",
      "|(3,[0,1,2],[0.2,0...|         2|\n",
      "|(3,[0,1,2],[9.0,9...|         0|\n",
      "|(3,[0,1,2],[9.1,9...|         0|\n",
      "|(3,[0,1,2],[9.2,9...|         0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a59533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
